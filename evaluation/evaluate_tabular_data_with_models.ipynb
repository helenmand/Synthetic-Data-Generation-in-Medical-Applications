{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_path = '../datasets/breast.csv'\n",
    "synthetic_data_path = '../synthetic/GCSbc.csv'\n",
    "target_variable = 'Diagnosis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data = pd.read_csv(real_data_path)\n",
    "real_data[target_variable] = real_data[target_variable].map({'M':0, 'B':1}) # M = malignant, B = benign\n",
    "#real_data = real_data.fillna(real_data.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_data = pd.read_csv(synthetic_data_path)\n",
    "synthetic_data[target_variable] = synthetic_data[target_variable].map({'M':0, 'B':1}) # M = malignant, B = benign\n",
    "#real_data = real_data.fillna(real_data.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in real data:       0\n",
      "Missing values in synthetic data:  0\n",
      "Duplicated rows in real data:      0\n",
      "Duplicated rows in synthetic data: 0\n"
     ]
    }
   ],
   "source": [
    "print('Missing values in real data:      ', real_data.isna().sum().sum())\n",
    "print('Missing values in synthetic data: ', synthetic_data.isna().sum().sum())\n",
    "print('Duplicated rows in real data:     ', real_data.duplicated().sum())\n",
    "print('Duplicated rows in synthetic data:', synthetic_data.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model in real data and evaluate in real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = real_data.drop(columns=[target_variable])\n",
    "y = real_data[target_variable]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:          0.9766081871345029\n",
      "Balanced Accuracy: 0.9748677248677249\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        63\n",
      "           1       0.98      0.98      0.98       108\n",
      "\n",
      "    accuracy                           0.98       171\n",
      "   macro avg       0.97      0.97      0.97       171\n",
      "weighted avg       0.98      0.98      0.98       171\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 61   2]\n",
      " [  2 106]]\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(solver='lbfgs', max_iter=10000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:         \", accuracy_score(y_test, y_pred_log_reg))\n",
    "print(\"Balanced Accuracy:\", balanced_accuracy_score(y_test, y_pred_log_reg))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_log_reg))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_log_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model in synthetic data and evaluate in real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = synthetic_data.drop(columns=[target_variable])\n",
    "y_train = synthetic_data[target_variable]\n",
    "X_test = real_data.drop(columns=[target_variable])\n",
    "y_test = real_data[target_variable]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9103690685413005\n",
      "Balanced Accuracy: 0.8845066328418161\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.78      0.87       212\n",
      "           1       0.88      0.99      0.93       357\n",
      "\n",
      "    accuracy                           0.91       569\n",
      "   macro avg       0.93      0.88      0.90       569\n",
      "weighted avg       0.92      0.91      0.91       569\n",
      "\n",
      "Confusion Matrix:\n",
      " [[166  46]\n",
      " [  5 352]]\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(solver='lbfgs', max_iter=10000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_log_reg))\n",
    "print(\"Balanced Accuracy:\", balanced_accuracy_score(y_test, y_pred_log_reg))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_log_reg))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_log_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9068541300527241\n",
      "Balanced Accuracy: 0.8845066328418161\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.78      0.86       212\n",
      "           1       0.88      0.98      0.93       357\n",
      "\n",
      "    accuracy                           0.91       569\n",
      "   macro avg       0.92      0.88      0.90       569\n",
      "weighted avg       0.91      0.91      0.90       569\n",
      "\n",
      "Confusion Matrix:\n",
      " [[165  47]\n",
      " [  6 351]]\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Balanced Accuracy:\", balanced_accuracy_score(y_test, y_pred_log_reg))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model in real data and evaluate in synthetic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consistency: If the model trained on the original data performs well on the synthetic data, it indicates that the synthetic data captures the underlying structure of the original data. This consistency suggests that the synthetic data maintains similar relationships and distributions as the original data.\n",
    "\n",
    "Generalizability: If the model trained on the original data generalizes well to the synthetic data, it suggests that the synthetic data is of high quality in terms of replicating the real-world phenomena represented in the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.708\n",
      "Balanced Accuracy: 0.7116666666666667\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.73      0.67       400\n",
      "           1       0.79      0.69      0.74       600\n",
      "\n",
      "    accuracy                           0.71      1000\n",
      "   macro avg       0.70      0.71      0.70      1000\n",
      "weighted avg       0.72      0.71      0.71      1000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[292 108]\n",
      " [184 416]]\n"
     ]
    }
   ],
   "source": [
    "X_train = real_data.drop(columns=[target_variable])\n",
    "y_train = real_data[target_variable]\n",
    "X_test = synthetic_data.drop(columns=[target_variable])\n",
    "y_test = synthetic_data[target_variable]\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Balanced Accuracy:\", balanced_accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a binary classifier to distinguish synthetic from real data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create unified dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius1</th>\n",
       "      <th>texture1</th>\n",
       "      <th>perimeter1</th>\n",
       "      <th>area1</th>\n",
       "      <th>smoothness1</th>\n",
       "      <th>compactness1</th>\n",
       "      <th>concavity1</th>\n",
       "      <th>concave_points1</th>\n",
       "      <th>symmetry1</th>\n",
       "      <th>fractal_dimension1</th>\n",
       "      <th>...</th>\n",
       "      <th>perimeter3</th>\n",
       "      <th>area3</th>\n",
       "      <th>smoothness3</th>\n",
       "      <th>compactness3</th>\n",
       "      <th>concavity3</th>\n",
       "      <th>concave_points3</th>\n",
       "      <th>symmetry3</th>\n",
       "      <th>fractal_dimension3</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.709474</td>\n",
       "      <td>17.476695</td>\n",
       "      <td>69.398366</td>\n",
       "      <td>338.236485</td>\n",
       "      <td>0.108580</td>\n",
       "      <td>0.109826</td>\n",
       "      <td>0.072458</td>\n",
       "      <td>0.026157</td>\n",
       "      <td>0.188342</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>...</td>\n",
       "      <td>75.051423</td>\n",
       "      <td>363.288781</td>\n",
       "      <td>0.141310</td>\n",
       "      <td>0.219094</td>\n",
       "      <td>0.264660</td>\n",
       "      <td>0.098792</td>\n",
       "      <td>0.309017</td>\n",
       "      <td>0.092970</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.241138</td>\n",
       "      <td>19.178663</td>\n",
       "      <td>81.630110</td>\n",
       "      <td>448.164079</td>\n",
       "      <td>0.107425</td>\n",
       "      <td>0.174473</td>\n",
       "      <td>0.127247</td>\n",
       "      <td>0.042195</td>\n",
       "      <td>0.212838</td>\n",
       "      <td>0.070528</td>\n",
       "      <td>...</td>\n",
       "      <td>89.025780</td>\n",
       "      <td>497.285206</td>\n",
       "      <td>0.143261</td>\n",
       "      <td>0.424374</td>\n",
       "      <td>0.317420</td>\n",
       "      <td>0.125984</td>\n",
       "      <td>0.302770</td>\n",
       "      <td>0.090073</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.180000</td>\n",
       "      <td>19.540000</td>\n",
       "      <td>133.800000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>0.113300</td>\n",
       "      <td>0.148900</td>\n",
       "      <td>0.213300</td>\n",
       "      <td>0.125900</td>\n",
       "      <td>0.172400</td>\n",
       "      <td>0.060530</td>\n",
       "      <td>...</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>1479.000000</td>\n",
       "      <td>0.166500</td>\n",
       "      <td>0.294200</td>\n",
       "      <td>0.530800</td>\n",
       "      <td>0.217300</td>\n",
       "      <td>0.303200</td>\n",
       "      <td>0.080750</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.159210</td>\n",
       "      <td>14.295529</td>\n",
       "      <td>78.301981</td>\n",
       "      <td>500.142786</td>\n",
       "      <td>0.090964</td>\n",
       "      <td>0.082822</td>\n",
       "      <td>0.052864</td>\n",
       "      <td>0.025740</td>\n",
       "      <td>0.154891</td>\n",
       "      <td>0.061356</td>\n",
       "      <td>...</td>\n",
       "      <td>87.967693</td>\n",
       "      <td>659.868033</td>\n",
       "      <td>0.127386</td>\n",
       "      <td>0.090102</td>\n",
       "      <td>0.074071</td>\n",
       "      <td>0.046125</td>\n",
       "      <td>0.200809</td>\n",
       "      <td>0.063206</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.682891</td>\n",
       "      <td>21.491931</td>\n",
       "      <td>87.941412</td>\n",
       "      <td>608.258029</td>\n",
       "      <td>0.090770</td>\n",
       "      <td>0.091571</td>\n",
       "      <td>0.079846</td>\n",
       "      <td>0.058876</td>\n",
       "      <td>0.161545</td>\n",
       "      <td>0.058330</td>\n",
       "      <td>...</td>\n",
       "      <td>96.477916</td>\n",
       "      <td>781.448539</td>\n",
       "      <td>0.134271</td>\n",
       "      <td>0.218461</td>\n",
       "      <td>0.198601</td>\n",
       "      <td>0.136597</td>\n",
       "      <td>0.219831</td>\n",
       "      <td>0.075611</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius1   texture1  perimeter1        area1  smoothness1  compactness1  \\\n",
       "0  10.709474  17.476695   69.398366   338.236485     0.108580      0.109826   \n",
       "1  12.241138  19.178663   81.630110   448.164079     0.107425      0.174473   \n",
       "2  20.180000  19.540000  133.800000  1250.000000     0.113300      0.148900   \n",
       "3  12.159210  14.295529   78.301981   500.142786     0.090964      0.082822   \n",
       "4  13.682891  21.491931   87.941412   608.258029     0.090770      0.091571   \n",
       "\n",
       "   concavity1  concave_points1  symmetry1  fractal_dimension1  ...  \\\n",
       "0    0.072458         0.026157   0.188342            0.074400  ...   \n",
       "1    0.127247         0.042195   0.212838            0.070528  ...   \n",
       "2    0.213300         0.125900   0.172400            0.060530  ...   \n",
       "3    0.052864         0.025740   0.154891            0.061356  ...   \n",
       "4    0.079846         0.058876   0.161545            0.058330  ...   \n",
       "\n",
       "   perimeter3        area3  smoothness3  compactness3  concavity3  \\\n",
       "0   75.051423   363.288781     0.141310      0.219094    0.264660   \n",
       "1   89.025780   497.285206     0.143261      0.424374    0.317420   \n",
       "2  146.000000  1479.000000     0.166500      0.294200    0.530800   \n",
       "3   87.967693   659.868033     0.127386      0.090102    0.074071   \n",
       "4   96.477916   781.448539     0.134271      0.218461    0.198601   \n",
       "\n",
       "   concave_points3  symmetry3  fractal_dimension3  Diagnosis  class  \n",
       "0         0.098792   0.309017            0.092970          1      1  \n",
       "1         0.125984   0.302770            0.090073          1      1  \n",
       "2         0.217300   0.303200            0.080750          0      0  \n",
       "3         0.046125   0.200809            0.063206          1      1  \n",
       "4         0.136597   0.219831            0.075611          0      1  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_data_copy = real_data.copy()\n",
    "synthetic_data_copy = synthetic_data.copy()\n",
    "\n",
    "real_data_copy['class'] = 0\n",
    "synthetic_data_copy['class'] = 1\n",
    "combined_data = pd.concat([real_data_copy, synthetic_data_copy], ignore_index=True)\n",
    "combined_data = combined_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = combined_data.drop(columns=[target_variable])\n",
    "y = combined_data[target_variable]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model to distinguish synthetic from real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8004246284501062\n",
      "Balanced Accuracy: 0.7956660231660231\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.78      0.74       175\n",
      "           1       0.86      0.81      0.84       296\n",
      "\n",
      "    accuracy                           0.80       471\n",
      "   macro avg       0.79      0.80      0.79       471\n",
      "weighted avg       0.81      0.80      0.80       471\n",
      "\n",
      "Confusion Matrix:\n",
      " [[136  39]\n",
      " [ 55 241]]\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Balanced Accuracy:\", balanced_accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ATML_SDV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
